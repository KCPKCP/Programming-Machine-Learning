{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e0e399",
   "metadata": {},
   "source": [
    "Keiland Pullen\n",
    "\n",
    "DSC 478 - Assignment 2 - part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b158ec",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cc56634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba702219",
   "metadata": {},
   "source": [
    "Change current working directory to homework/data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c211d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Home/Desktop/DePaul/Winter - DSC - 478 - Programming Machine Learning/Week 4/Homework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ec1eded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Home\\\\Desktop\\\\DePaul\\\\Winter - DSC - 478 - Programming Machine Learning\\\\Week 4\\\\Homework'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189df94",
   "metadata": {},
   "source": [
    "Problem 1a.) Create your own K-Nearest -Neighbor classifier function.  Your classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "307e9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(x, D, L, K, measure):\n",
    "    if measure == 0:\n",
    "        #euclidean distance\n",
    "        dist = np.sqrt(((D - x)**2).sum(axis=1))\n",
    "    elif measure == 1:\n",
    "        #cosine distance\n",
    "        D_norm = np.array([np.linalg.norm(D[i]) for i in range(len(D))])\n",
    "        x_norm = np.linalg.norm(x)\n",
    "        cosine = np.dot(D,x)/(D_norm * x_norm)\n",
    "        dist = 1 - cosine\n",
    "    idx = np.argsort(dist)\n",
    "    count = {}\n",
    "    for i in range(K):\n",
    "        voteLabel = L[idx[i]]\n",
    "        count[voteLabel] = count.get(voteLabel,0) + 1\n",
    "        sortedClassCount = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0], idx[:K]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba145716",
   "metadata": {},
   "source": [
    "Problem 1b.) Create an evaluation function to measure the accuracy of your classifier. This funcion will call..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb20a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierAccuracy(A, x, D, L, K, measure):\n",
    "    numberLabels = len(A)\n",
    "    errorCount = 0.0\n",
    "    for i in range(numberLabels):\n",
    "        classifierResult, neigh_idx = knn_classifier(x[i,:], D, L, K, measure)\n",
    "        if (classifierResult != A[i]):\n",
    "            errorCount = errorCount + 1.0\n",
    "    error = errorCount / float(numberLabels)\n",
    "    return error   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d70ef",
   "metadata": {},
   "source": [
    "Problem 1c.) Run your evaluation function on a range of values for K from 5 to 100 (in increments of 5) in order to compare accuracy values for different numbers of neighbors.  Do this both for..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65fd8e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Home\\\\Desktop\\\\DePaul\\\\Winter - DSC - 478 - Programming Machine Learning\\\\Week 4\\\\Homework'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "495a0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01e02f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Home\\\\Desktop\\\\DePaul\\\\Winter - DSC - 478 - Programming Machine Learning\\\\Week 4\\\\Homework\\\\newsgroups'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.genfromtxt('trainMatrixModified.txt', dtype=float)\n",
    "trainLabels = np.genfromtxt('trainClasses.txt', dtype=int, usecols = (1) )\n",
    "trainD = trainData.T\n",
    "\n",
    "testData = np.genfromtxt('testMatrixModified.txt', dtype=float)\n",
    "testLabels = np.genfromtxt('testClasses.txt', usecols=(1),dtype=int)\n",
    "testD = testData.T\n",
    "\n",
    "result = np.zeros((20,3), dtype=float)\n",
    "for i in range(0,20):\n",
    "    EucErrorRate = classifierAccuracy(testLabels, testD, trainD, trainLabels, i+1, 0)\n",
    "    CosErrorRate = classifierAccuracy(testLabels, testD, trainD, trainLabels, i+1, 1)\n",
    "    result[i] = [i+1, EucErrorRate, CosErrorRate]\n",
    "    \n",
    "print(\" For K    Euc Error Rate   Cosine Error Rate\")\n",
    "for row in result:\n",
    "    print(\"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [result[i][0] for i in range (len(result))]\n",
    "euclid  =  [result[i][1] for i in range (len(result))]\n",
    "cosin  =  [result[i][2] for i in range (len(result))]\n",
    "    \n",
    "plt.plot(k, euclid, label = \"Euclidean\")\n",
    "plt.plot(k, cosin, label = \"Cosine\" )\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bab44",
   "metadata": {},
   "source": [
    "Problem 1d.) Next, Modify the training and test data sets so that term weights are converted to TFxIDF weights (instead of raw term frequencies).  Then, rerun your evaluation (only for Cosine similarity measure version of the classifier) on the range of K values as above and create a chart comparing the results with and without using TFxIDF weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a3b80",
   "metadata": {},
   "source": [
    "Concatenate the Data Frame, Calculate the document frequencies, Create matrix of all entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "theData = np.concatenate((trainData, testData), axis=1)\n",
    "dataFrame = np.array([(theData != 0).sum(1)]).T\n",
    "TotalDocs = len(theData[0,:])\n",
    "NMatrix = np.ones(np.shape(theData), dtype=float) * TotalDocs\n",
    "IDF = np.log2(np.divide(NMatrix, dataFrame))\n",
    "TD_TFIDF = IDF * theData\n",
    "\n",
    "print(NMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5d368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DT_TFIDF = TD_TFIDF.T\n",
    "trainNum = 0.8 * len(DT_TFIDF)\n",
    "Train_TD_TFIDF = DT_TFIDF[:int(trainNum),:]\n",
    "Test_TD_TFIDF = DT_TFIDF[int(trainNum):,:]\n",
    "\n",
    "#print(trainNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d517e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = np.zeros((20,3), dtype=float)\n",
    "for i in range(0,20):\n",
    "    EucErrorRate = classifierAccuracy(testLabels, testD, trainD, trainLabels, i+1, 0)\n",
    "    CosErrorRate = classifierAccuracy(testLabels, Test_TD_TFIDF, Train_TD_TFIDF, trainLabels, i+1, 1)\n",
    "    result2[i] = [i+1, EucErrorRate, CosErrorRate]\n",
    "    \n",
    "print(\" For K   Euc Error Rate Cosine Error Rate\")\n",
    "for row in result2:\n",
    "    print(\"%2.0f   %.2f\" % (row[0], row[1], row[2]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c382d3d",
   "metadata": {},
   "source": [
    "Problem 1e.) Create a new classifier based on the Rocchio Method (also known as the \"nearest centroid\" method) adapted for text categorization. You should..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866ff32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9809a3d2",
   "metadata": {},
   "source": [
    "Problem 1f.) Using scikit-learns Nearest Centroid classifier to perform classification of the test instances, as in the previous part. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c30cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0fed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
